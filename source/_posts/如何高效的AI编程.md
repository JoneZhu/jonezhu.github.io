---
title: 如何高效的AI编程
date: 2025-09-14 11:10:28
categories:
  - 技术
  - 方法论
---
在新的AI编程辅助范式下，我们的生产效率和生产工艺都发生了转变。经过近1年的尝试，对AI辅助编程有了一个比较清晰的认知，然而，我们需要澄清一个常见误解：

**我们讨论的不是随意将idea生成系统的效率**。你可能看到过有人和AI说"我要生成一个问卷系统"，AI就能快速完成。但这种演示场景与实际工程开发存在本质差异。

**我们讨论的是对结果有严格预期的功能开发效率**。有几年工作经验的同学都见过公司里那种几千字甚至上万字的需求文档。在实际业务中，可能仅仅是漏看了一两句话，最终的业务验收和产品经理验收就会不通过。

因此，在当前范式下实现高效生产的关键在于：**提示词编写的高效性**、**生成结果高度符合预期**，以及**通过AI辅助测试验证系统运行结果**。

如果正常开发一个功能需要两天时间，而使用AI辅助开发却要花费一天时间编写提示词和测试验证，那么这种"高效"就失去了意义。

## 核心要素：三个关键维度

### 1. 编写提示词高效

编写提示词本身是一项相当耗时的工作。对于稍微复杂的功能，花费2-3个小时编写提示词都是很正常的。

#### 高效编写提示词的关键：方法论积累

关键在于将**反复出现的通用描述**积累下来，形成可复用的方法论。

**项目级通用方法论示例**：

- 在当前项目下（前后端集成、Java、C端B端集成）一个新的后台管理页面接入到当前系统的正确姿势
- 新功能模块的标准开发流程和架构规范
- 数据库设计规范和命名约定
- API接口设计标准和文档格式

**功能级通用方法论示例**： 以Flutter项目为例，当需要在某个表添加字段时，涉及的改动范围是固定的：

- Database文件修改
- Model类更新
- 实体文件调整
- Dao文件变更
- Repository文件修改

#### 实践建议

1. **建立方法论文档库**
    - 将这些通用方法论整理成markdown文件
    - 统一放在项目的`docs`目录下
    - 按功能类型和复杂度分类组织
2. **复用而非重写**
    - 加新字段时，直接引入相应的方法论文档
    - 避免每次重复描述相同的技术细节
    - 在方法论基础上补充具体的业务需求
3. **持续优化积累**
    - 每次使用后根据实际效果优化方法论
    - 记录AI生成代码中的常见问题和解决方案
    - 建立团队共享的最佳实践库

#### 提示词模板示例

以下是一个相对粗糙但实用的提示词结构模板，可以根据实际项目需求进行调整：

markdown

```markdown
## 预期内容输出给AI

### 用户层
- **功能说明**：详细描述功能的业务目标和用户场景
- **样式**：UI设计要求、颜色规范、布局方式
- **交互**：用户操作流程、响应反馈、异常处理

### 代码实现层  
- **组件架构/层级**：模块划分、文件结构、依赖关系
- **接口**：
  - 组件间数据交换的数据结构
  - 存储到数据库的数据结构  
  - 前后端交互的API规范
```

**使用说明**： 这个模板比较粗糙，但涵盖了AI生成代码时需要的核心信息。在实际使用中，你可以：

- 根据项目复杂度调整详细程度
- 针对不同类型的功能（CRUD、报表、工具类等）创建专门的子模板
- 逐步完善每个部分的具体描述格式

建议先用这个基础结构试验几次，根据AI的反馈效果来优化模板内容。

### 2. AI生成结果高效且符合预期

理想情况下，AI应该能够**一次性生成**高度符合我们预期的代码结果。

**"一次性"的含义**：

- 尽量避免超出AI工具的上下文限制
- 功能颗粒度要合理控制
- 代码上下文颗粒度要适中，避免出现3000-5000行的单个类文件
- 减轻对AI工具上下文和大模型处理能力的压力

#### 如何生成高度符合预期的代码

**完整而详细的描述包括**：

**主体描述**：

- 功能的完整描述
- 页面解决什么问题
- 包含哪些表单和界面元素
- 主体颜色和设计风格

**技术细节**：

- 包含的功能和接口
- 代码架构设计
- 技术详细设计
- 后端接口规范（参数、接口文档）
- 数据库设计

**现有代码改造场景**： 当需要对现有代码进行大量改造时，在实际生成代码之前：

- 让AI帮助确认我们的设计方案是否可行
- 验证设计是否符合现有技术方案
- 让AI帮助查漏补缺

### 3. AI辅助测试：验证系统运行结果

#### 测试验证的痛点

即使我们快速编写了上下文并生成了符合预期的代码，现实世界是复杂的。我们仍然需要通过充足的集成测试来验证系统的运行结果是否符合预期。这部分测试验证同样比较耗时，而AI可以有效辅助我们完成这项工作。

#### AI辅助测试的实现

**后端工程测试**（相对简单）：

- 让AI帮助完成初步的冒烟测试
- 让AI编写测试用例
- 直接在终端启动后端服务
- 通过curl工具拼装参数，模拟调用后端接口
- 验证数据库和后端日志是否符合预期
- 可以让AI通过MCP直接访问数据库进行验证

**前端/客户端工程测试**（困难且复杂）：

- 直接让AI帮助进行集成测试存在较大技术难度
- 涉及UI渲染、用户交互、设备兼容性等复杂场景
- 这些都是未来值得探索的技术方向
- 目前更多依赖传统的手工测试和自动化测试框架

## 写在最后

回顾最近一年使用AI编程工具的经历，我经历了大量的试错过程。从最初的磕磕绊绊，到现在能够相对高效地使用AI工具，这个过程让我深刻体会到：真正的效率提升来自于**积累通用提示词**和**详细的功能技术实现描述**这两个看似简单却极其重要的实践。

当我们建立起自己的方法论库，当我们学会用精确的语言描述需求和技术细节，AI工具就真正成为了我们的得力助手。这不仅仅是工具使用技巧的问题，更是思维方式的转变——从"让AI猜测我的意图"到"与AI精确协作"。

当然，AI辅助测试领域还有很大的探索空间，特别是前端和客户端的集成测试。但我相信，随着AI工具的持续升级和技术的发展，未来会有更加高效、更加智能的AI Coding方式出现。

对于还在摸索中的同学们，我想说：不要害怕试错，每一次不完美的尝试都是在为更高效的协作打基础。AI编程的路还很长，但方向已经很明确了。